{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47bb49cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.getcwd() /home/carson/Desktop/Projects/language_reinforce/notebooks\n",
      "3.7.5 (default, Dec  9 2021, 17:04:37) \n",
      "[GCC 8.4.0]\n",
      "torch.__version__ 1.12.1+cu102\n",
      "0 cuda\n",
      "transformers.__version__ 4.22.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('os.getcwd()', os.getcwd())\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "print(sys.version)\n",
    "import time\n",
    "\n",
    "#plotting tools\n",
    "from matplotlib import pyplot as plt \n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "#torch libs\n",
    "import torch\n",
    "print('torch.__version__', torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipe_device = 0 if torch.cuda.is_available() else -1\n",
    "print(pipe_device, device)\n",
    "\n",
    "#huggingface transformers\n",
    "import transformers\n",
    "print('transformers.__version__',transformers.__version__)\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2PreTrainedModel\n",
    "\n",
    "\n",
    "#curious\n",
    "from curious.models import GPT2HeadWithValueModel\n",
    "from curious.rl import PPOTrainer\n",
    "from curious.utils import LengthSampler, collater, respond_to_batch, generate_text\n",
    "\n",
    "#jupyter stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbf1175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/carson/Desktop/Projects/modelstates/distilgpt2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cache_folder = '/Users/carson/projects/modelstates' \n",
    "cache_folder = '/home/carson/Desktop/Projects/modelstates'\n",
    "model_name = 'distilgpt2' #'gpt2' # 'gpt2-xl' # 'gpt2-large' #\n",
    "cache_dir = os.path.join(cache_folder, model_name)\n",
    "cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399b95a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    pad_token='<|endoftext|>',\n",
    "    padding_side = 'left',\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir = cache_dir, \n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c2fc9a",
   "metadata": {},
   "source": [
    "```\n",
    "GPT2LMHeadModel(\n",
    "  (transformer): GPT2Model(\n",
    "    (wte): Embedding(50257, 768)\n",
    "    (wpe): Embedding(1024, 768)\n",
    "    (drop): Dropout(p=0.1, inplace=False)\n",
    "    (h): ModuleList(\n",
    "      (i): GPT2Block(\n",
    "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "        (attn): GPT2Attention(\n",
    "          (c_attn): Conv1D()\n",
    "          (c_proj): Conv1D()\n",
    "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
    "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
    "        )\n",
    "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "        (mlp): GPT2MLP(\n",
    "          (c_fc): Conv1D()\n",
    "          (c_proj): Conv1D()\n",
    "          (act): NewGELUActivation()\n",
    "          (dropout): Dropout(p=0.1, inplace=False)\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "  )\n",
    "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73953d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50257, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1445, -0.0455,  0.0042,  ..., -0.1523,  0.0184,  0.0991],\n",
       "        [ 0.0573, -0.0722,  0.0234,  ...,  0.0603, -0.0042,  0.0478],\n",
       "        [-0.1106,  0.0386,  0.1948,  ...,  0.0421, -0.1141, -0.1455],\n",
       "        ...,\n",
       "        [-0.0710, -0.0173,  0.0176,  ...,  0.0834,  0.1340, -0.0746],\n",
       "        [ 0.1993,  0.0201,  0.0151,  ..., -0.0829,  0.0750, -0.0294],\n",
       "        [ 0.0342,  0.0640,  0.0305,  ...,  0.0291,  0.0942,  0.0639]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.lm_head.weight.shape)\n",
    "model.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c038e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['transformer.h.3.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'v_head.summary.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'v_head.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50257, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1445, -0.0455,  0.0042,  ..., -0.1523,  0.0184,  0.0991],\n",
       "        [ 0.0573, -0.0722,  0.0234,  ...,  0.0603, -0.0042,  0.0478],\n",
       "        [-0.1106,  0.0386,  0.1948,  ...,  0.0421, -0.1141, -0.1455],\n",
       "        ...,\n",
       "        [-0.0710, -0.0173,  0.0176,  ...,  0.0834,  0.1340, -0.0746],\n",
       "        [ 0.1993,  0.0201,  0.0151,  ..., -0.0829,  0.0750, -0.0294],\n",
       "        [ 0.0342,  0.0640,  0.0305,  ...,  0.0291,  0.0942,  0.0639]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_model = GPT2HeadWithValueModel.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "print(gpt2_model.lm_head.weight.shape)\n",
    "gpt2_model.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79660296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the first rule of robotics is that you never set a rule regarding speed, but you just want to look at']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(gpt2_model, tokenizer, prompt = \"the first rule of robotics is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c630c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
