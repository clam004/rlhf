{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.getcwd() /Users/carson/projects/language_reinforce/notebooks\n",
      "3.10.6 (main, Aug 30 2022, 05:09:33) [Clang 12.0.0 (clang-1200.0.32.29)]\n",
      "torch.__version__ 1.12.1\n",
      "transformers.__version__ 4.22.2\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('os.getcwd()', os.getcwd())\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "print(sys.version)\n",
    "import time\n",
    "\n",
    "#plotting tools\n",
    "from matplotlib import pyplot as plt \n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "#torch libs\n",
    "import torch\n",
    "print('torch.__version__', torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipe_device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "#huggingface transformers\n",
    "import transformers\n",
    "print('transformers.__version__',transformers.__version__)\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "#curious\n",
    "from curious.models import GPT2HeadWithValueModel\n",
    "from curious.rl import PPOTrainer\n",
    "from curious.utils import LengthSampler, collater, respond_to_batch\n",
    "\n",
    "#jupyter stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/carson/projects/modelstates/distilgpt2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_folder = '/Users/carson/projects/modelstates' #'/home/carson/Desktop/Projects/modelstates'\n",
    "model_name = 'distilgpt2'#'gpt2' # 'gpt2-xl' # 'gpt2-large' #\n",
    "cache_dir = os.path.join(cache_folder, model_name)\n",
    "cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['transformer.h.5.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'v_head.summary.weight', 'transformer.h.4.attn.masked_bias', 'v_head.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['transformer.h.5.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'v_head.summary.weight', 'transformer.h.4.attn.masked_bias', 'v_head.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "gpt2_model = GPT2HeadWithValueModel.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "gpt2_model_ref = GPT2HeadWithValueModel.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.10.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.3.attn.masked_bias', 'lm_head.weight', 'h.9.attn.masked_bias', 'h.6.attn.masked_bias', 'h.11.attn.masked_bias', 'h.5.attn.masked_bias', 'v_head.summary.weight', 'h.4.attn.masked_bias', 'h.1.attn.masked_bias', 'h.0.attn.masked_bias', 'h.2.attn.masked_bias', 'v_head.summary.bias']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/carson/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "Loading cached processed dataset at /Users/carson/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-e68378636d846987.arrow\n"
     ]
    }
   ],
   "source": [
    "# load imdb with datasets\n",
    "ds = load_dataset('imdb', split='train')\n",
    "ds = ds.rename_columns({'text': 'review', 'label': 'sentiment'})\n",
    "ds = ds.filter(lambda x: len(x[\"review\"])>200, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reward model used to assign reward to model's outputs\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\",\"lvwerra/distilbert-imdb\", device=pipe_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carson/projects/language_reinforce/venv/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:89: UserWarning: `return_all_scores` is now deprecated, use `top_k=1` if you want similar functionnality\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 2.335047721862793},\n",
       "  {'label': 'POSITIVE', 'score': -2.7265758514404297}]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reward model configs\n",
    "sent_kwargs = {\n",
    "    \"return_all_scores\": True,\n",
    "    \"function_to_apply\": \"none\",\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "text = 'this movie was really bad!!'\n",
    "sentiment_pipe(text, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2d608bb86f4573b99ff07c7ac44cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24895 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# modify the dataset with a new tokens column and query column\n",
    "# these are used in the data feeder of the main train loop\n",
    "\n",
    "input_size = LengthSampler(min_value = 4, max_value = 8)\n",
    "output_size = LengthSampler(min_value = 4, max_value = 16)\n",
    "\n",
    "def map_tokenize(sample):\n",
    "    \n",
    "    '''\n",
    "    this function is applied to the dataset and \n",
    "    only the first few tokens of review are used for \"tokens\"\n",
    "    they are decoded and stored as query in their text form\n",
    "    '''\n",
    "    \n",
    "    sample[\"tokens\"] = gpt2_tokenizer.encode(sample[\"review\"])[:input_size()]\n",
    "    sample[\"query\"] = gpt2_tokenizer.decode(sample[\"tokens\"])\n",
    "    \n",
    "    return sample\n",
    "\n",
    "ds = ds.map(map_tokenize, batched=False)\n",
    "dataloader = torch.utils.data.DataLoader(ds, batch_size=32, collate_fn=collater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_name\": \"lvwerra/gpt2-imdb\",\n",
    "    \"cls_model_name\": \"lvwerra/distilbert-imdb\",\n",
    "    \"steps\": 20000,\n",
    "    \"batch_size\": 32, \n",
    "    \"forward_batch_size\": 16,\n",
    "    \"ppo_epochs\": 4,   \n",
    "    \"txt_in_min_len\": 4,\n",
    "    \"txt_in_max_len\": 8,\n",
    "    \"txt_out_min_len\": 4,\n",
    "    \"txt_out_max_len\": 16,\n",
    "    \"lr\": 1e-5,\n",
    "    \"init_kl_coef\":0.2,\n",
    "    \"target\": 6,\n",
    "    \"horizon\":10000,\n",
    "    \"gamma\":1,\n",
    "    \"lam\":0.95,\n",
    "    \"cliprange\": .2,\n",
    "    \"cliprange_value\":.2,\n",
    "    \"vf_coef\":.1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6583f2aa95e4413f97a521dd53b5c472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instantiate the reinforcement learning trainer\n",
    "reward_list = []\n",
    "\n",
    "ppo_trainer = PPOTrainer(gpt2_model, gpt2_model_ref, gpt2_tokenizer, **config)\n",
    "\n",
    "total_ppo_epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "for epoch, batch in tqdm(zip(range(total_ppo_epochs), iter(dataloader)), total = total_ppo_epochs):\n",
    "    \n",
    "    ### initiate logging dicts\n",
    "    logs, timing = dict(), dict()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ### get start sequence input tokens\n",
    "    query_tensors = [torch.tensor(t).long().to(device) for t in batch[\"tokens\"]]\n",
    "    \n",
    "    ### Get responses from policy model\n",
    "    t = time.time()\n",
    "    response_tensors = []\n",
    "    for i in range(batch_size):\n",
    "        gen_len = output_size()\n",
    "        query_tensor = query_tensors[i].unsqueeze(dim=0)\n",
    "        response_tensor = respond_to_batch(gpt2_model, query_tensor, gen_len)\n",
    "        response_tensors.append(response_tensor.squeeze())\n",
    "        \n",
    "    batch['response'] = [gpt2_tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "    timing['time/get_response'] = time.time()-t\n",
    "    \n",
    "    #### Compute sentiment score (reward)\n",
    "    t = time.time()\n",
    "    texts = [q + r for q,r in zip(batch['query'], batch['response'])]\n",
    "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
    "    rewards = torch.tensor([output[1][\"score\"] for output in pipe_outputs]).to(device)\n",
    "    timing['time/get_sentiment_preds'] = time.time()-t\n",
    "    \n",
    "    reward_list.append(torch.mean(rewards).item())\n",
    "    \n",
    "    #### Run PPO step \n",
    "    t = time.time()\n",
    "    train_stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    timing['time/optimization'] = time.time()-t\n",
    "    \n",
    "plt.figure()\n",
    "plt.xlabel('Epochs', fontsize=25)\n",
    "plt.ylabel('Rewards', fontsize=25)\n",
    "plt.plot(reward_list, label='sentiment')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
