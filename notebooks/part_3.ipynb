{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026bbb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.getcwd() /Users/carson/projects/language_reinforce/notebooks\n",
      "3.10.6 (main, Aug 30 2022, 05:09:33) [Clang 12.0.0 (clang-1200.0.32.29)]\n",
      "torch.__version__ 1.12.1\n",
      "-1 cpu\n",
      "transformers.__version__ 4.22.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('os.getcwd()', os.getcwd())\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "print(sys.version)\n",
    "import time\n",
    "\n",
    "#plotting tools\n",
    "from matplotlib import pyplot as plt \n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "#torch libs\n",
    "import torch\n",
    "print('torch.__version__', torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipe_device = 0 if torch.cuda.is_available() else -1\n",
    "print(pipe_device, device)\n",
    "\n",
    "#huggingface transformers\n",
    "import transformers\n",
    "print('transformers.__version__',transformers.__version__)\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2PreTrainedModel\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "#curious\n",
    "from curious.models import GPT2HeadWithValueModel\n",
    "from curious.rl import PPOTrainer\n",
    "from curious.utils import LengthSampler, collater, respond_to_batch, generate_text\n",
    "\n",
    "#jupyter stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48b48dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/carson/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load imdb with datasets\n",
    "ds = load_dataset('imdb', split='train')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcdb0e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\",\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e72f9af",
   "metadata": {},
   "source": [
    "```\n",
    "Found cached dataset imdb (/home/carson/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
    "Loading cached processed dataset at /home/carson/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-fa8f4f047f540716.arrow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d762a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/carson/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-e68378636d846987.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['review', 'sentiment'],\n",
       "    num_rows: 24895\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename teh columns\n",
    "ds = ds.rename_columns({'text': 'review', 'label': 'sentiment'})\n",
    "# \n",
    "ds = ds.filter(lambda x: len(x[\"review\"])>200, batched=False)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56d28203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[2]['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b615e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "4\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "7\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "input_size = LengthSampler(min_value = 4, max_value = 8)\n",
    "output_size = LengthSampler(min_value = 4, max_value = 16)\n",
    "\n",
    "for i in range(10):\n",
    "    print(input_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b67e375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957a5438954e4283b4091babf313ad0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86633f2dc2845ae95099caa9b914d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717359e06fbb4632a57e5f1def48489b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a99a07970c4028bf4b3240ccf50a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'gpt2',\n",
    "    pad_token='<|endoftext|>',\n",
    "    padding_side = 'left',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac14f165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfd372fe3514b919b6f7d848dd6a4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24895 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "def map_tokenize(sample):\n",
    "    \n",
    "    '''\n",
    "    this function is applied to the dataset and \n",
    "    only the first few tokens of review are used for \"tokens\"\n",
    "    they are decoded and stored as query in their text form\n",
    "    '''\n",
    "    \n",
    "    sample[\"tokens\"] = gpt2_tokenizer.encode(sample[\"review\"])[:input_size()]\n",
    "    sample[\"query\"] = gpt2_tokenizer.decode(sample[\"tokens\"])\n",
    "    \n",
    "    return sample\n",
    "\n",
    "ds = ds.map(map_tokenize, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29741d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\",\n",
       " 'sentiment': 0,\n",
       " 'tokens': [1532, 691, 284, 3368, 1642],\n",
       " 'query': 'If only to avoid making'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbc4a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collater(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(ds, batch_size=2, collate_fn=collater)\n",
    "\n",
    "type(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f20144cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "277cf1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> dict_keys(['review', 'sentiment', 'tokens', 'query'])\n",
      "['I rented I AM C', '\"I Am Curious']\n",
      "[[40, 26399, 314, 3001, 327], [1, 40, 1703, 44269]]\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "\n",
    "print(type(batch), batch.keys())\n",
    "print(batch['query'])\n",
    "print(batch['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4080c7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([   40, 26399,   314,  3001,   327]),\n",
       " tensor([    1,    40,  1703, 44269])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tensors = [torch.tensor(t).long().to(device) for t in batch[\"tokens\"]]\n",
    "query_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad435e",
   "metadata": {},
   "source": [
    "```python\n",
    "input_ids = self.data_collator([torch.cat([q, r]) for q, r in zip(query_batch, response_batch)])[\"input_ids\"]\n",
    "with torch.no_grad():\n",
    "    logits, _, v = self.model(input_ids)\n",
    "    ref_logits, _, _ = self.ref_model(input_ids)\n",
    "logprobs = logprobs_from_logits(logits[:,:-1,:], input_ids[:,1:])\n",
    "ref_logprobs = logprobs_from_logits(ref_logits[:,:-1,:], input_ids[:,1:])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c72731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
