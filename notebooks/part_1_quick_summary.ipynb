{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant to allow you to run a fast beginning to end training and validation toy experiment on a small model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.getcwd() /home/carson/rlhf/notebooks\n",
      "3.8.10 (default, Nov 14 2022, 12:59:47) \n",
      "[GCC 9.4.0]\n",
      "torch.__version__ 1.11.0+cu113\n",
      "0 cuda\n",
      "transformers.__version__ 4.25.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('os.getcwd()', os.getcwd())\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "print(sys.version)\n",
    "import time\n",
    "\n",
    "#plotting tools\n",
    "from matplotlib import pyplot as plt \n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "#torch libs\n",
    "import torch\n",
    "print('torch.__version__', torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipe_device = 0 if torch.cuda.is_available() else -1\n",
    "print(pipe_device, device)\n",
    "\n",
    "#huggingface transformers\n",
    "import transformers\n",
    "print('transformers.__version__',transformers.__version__)\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "#curious\n",
    "from rlhf.models import GPT2HeadWithValueModel\n",
    "from rlhf.rl import PPOTrainer\n",
    "from rlhf.utils import LengthSampler, collater, respond_to_batch\n",
    "\n",
    "#jupyter stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['v_head.summary.bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'v_head.summary.weight', 'transformer.h.3.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['v_head.summary.bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'v_head.summary.weight', 'transformer.h.3.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_name = 'distilgpt2' #'gpt2' # 'gpt2-xl' # 'gpt2-large' #\n",
    "\n",
    "gpt2_model = GPT2HeadWithValueModel.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "gpt2_model_reference = GPT2HeadWithValueModel.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "# put models onto GPU\n",
    "gpt2_model.to(device);\n",
    "gpt2_model_reference.to(device);\n",
    "\n",
    "print(\"gpt2_model.device\", gpt2_model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Warning is expected\n",
    "\n",
    "```\n",
    "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.10.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.3.attn.masked_bias', 'lm_head.weight', 'h.9.attn.masked_bias', 'h.6.attn.masked_bias', 'h.11.attn.masked_bias', 'h.5.attn.masked_bias', 'v_head.summary.weight', 'h.4.attn.masked_bias', 'h.1.attn.masked_bias', 'h.0.attn.masked_bias', 'h.2.attn.masked_bias', 'v_head.summary.bias']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a64801c035b438a84cafc4960fc2bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeda061335ef4497900bb2e1b6a205f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d9b23152ac4699b373a49ee92a711c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/carson/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceaa5e8a107f44dd9ecc785e24992f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load imdb with datasets\n",
    "ds = load_dataset('imdb', split='train')\n",
    "ds = ds.rename_columns({'text': 'review', 'label': 'sentiment'})\n",
    "ds = ds.filter(lambda x: len(x[\"review\"])>200, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65399e528dbe4158b3c8acf5b8e10966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf8576febce4c9eb42f210c9ad2b4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d33dd50492c4089a01276845a77dfa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1dcc9bb3e4c42a0ba0c4034ec4fde86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b117ca4224545ea8b77818b0eaa61a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e09574b779b4caf8f96914c1e480bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the reward model used to assign reward to model's outputs\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\",\"lvwerra/distilbert-imdb\", device=pipe_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carson/rlhf/venv/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 2.3350484371185303},\n",
       "  {'label': 'POSITIVE', 'score': -2.726576328277588}]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reward model configs\n",
    "sent_kwargs = {\n",
    "    \"return_all_scores\": True,\n",
    "    \"function_to_apply\": \"none\",\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "text = 'this movie was really bad!!'\n",
    "sentiment_pipe(text, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ada062829a4adea09a0953728ab762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f8b3096f254dcf93d626bba6151572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a92a8bec4304db6959afe62e871c3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the tokenizer\n",
    "\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879f5d35ba7443f98d0a3e0a340d20ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24895 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# modify the dataset with a new tokens column and query column\n",
    "# these are used in the data feeder of the main train loop\n",
    "\n",
    "input_size = LengthSampler(min_value = 4, max_value = 8)\n",
    "output_size = LengthSampler(min_value = 4, max_value = 16)\n",
    "\n",
    "def map_tokenize(sample):\n",
    "    \n",
    "    '''\n",
    "    this function is applied to the dataset and \n",
    "    only the first few tokens of review are used for \"tokens\"\n",
    "    they are decoded and stored as query in their text form\n",
    "    '''\n",
    "    \n",
    "    sample[\"tokens\"] = gpt2_tokenizer.encode(sample[\"review\"])[:input_size()]\n",
    "    sample[\"query\"] = gpt2_tokenizer.decode(sample[\"tokens\"])\n",
    "    \n",
    "    return sample\n",
    "\n",
    "ds = ds.map(map_tokenize, batched=False)\n",
    "dataloader = torch.utils.data.DataLoader(ds, batch_size=32, collate_fn=collater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_name\": \"lvwerra/gpt2-imdb\",\n",
    "    \"cls_model_name\": \"lvwerra/distilbert-imdb\",\n",
    "    \"steps\": 20000,\n",
    "    \"batch_size\": 32, \n",
    "    \"forward_batch_size\": 16,\n",
    "    \"ppo_epochs\": 4,   \n",
    "    \"txt_in_min_len\": 4,\n",
    "    \"txt_in_max_len\": 8,\n",
    "    \"txt_out_min_len\": 4,\n",
    "    \"txt_out_max_len\": 16,\n",
    "    \"lr\": 1e-5,\n",
    "    \"init_kl_coef\":0.2,\n",
    "    \"target\": 6,\n",
    "    \"horizon\":10000,\n",
    "    \"gamma\":1,\n",
    "    \"lam\":0.95,\n",
    "    \"cliprange\": .2,\n",
    "    \"cliprange_value\":.2,\n",
    "    \"vf_coef\":.1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa205da37ca4f7791a9cd82ccfd01fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carson/rlhf/venv/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# instantiate the reinforcement learning trainer\n",
    "reward_list = []\n",
    "\n",
    "ppo_trainer = PPOTrainer(gpt2_model, gpt2_model_reference, gpt2_tokenizer, **config)\n",
    "\n",
    "total_ppo_epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "for epoch, batch in tqdm(zip(range(total_ppo_epochs), iter(dataloader)), total = total_ppo_epochs):\n",
    "    \n",
    "    ### initiate logging dicts\n",
    "    logs, timing = dict(), dict()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    ### get start sequence input tokens\n",
    "    query_tensors = [torch.tensor(t).long().to(device) for t in batch[\"tokens\"]]\n",
    "    \n",
    "    ### Get responses from policy model\n",
    "    t = time.time()\n",
    "    response_tensors = []\n",
    "    for i in range(batch_size):\n",
    "        gen_len = output_size()\n",
    "        query_tensor = query_tensors[i].unsqueeze(dim=0)\n",
    "        response_tensor = respond_to_batch(gpt2_model, query_tensor, gen_len)\n",
    "        response_tensors.append(response_tensor.squeeze())\n",
    "        \n",
    "    batch['response'] = [gpt2_tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "    timing['time/get_response'] = time.time()-t\n",
    "    \n",
    "    #### Compute sentiment score (reward)\n",
    "    t = time.time()\n",
    "    texts = [q + r for q,r in zip(batch['query'], batch['response'])]\n",
    "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
    "    rewards = torch.tensor([output[1][\"score\"] for output in pipe_outputs]).to(device)\n",
    "    timing['time/get_sentiment_preds'] = time.time()-t\n",
    "    \n",
    "    reward_list.append(torch.mean(rewards).item())\n",
    "    \n",
    "    #### Run PPO step \n",
    "    t = time.time()\n",
    "    train_stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    timing['time/optimization'] = time.time()-t\n",
    "    \n",
    "plt.figure()\n",
    "plt.xlabel('Epochs', fontsize=25)\n",
    "plt.ylabel('Rewards', fontsize=25)\n",
    "plt.plot(reward_list, label='sentiment')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expected reward vs epochs graph\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/clam004/rlhf/main/sample_files/rewards_epochs.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(batch[\"query\"])):\n",
    "    print(' ')\n",
    "    print(batch[\"query\"][i] + '  -->  ' + batch['response'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
