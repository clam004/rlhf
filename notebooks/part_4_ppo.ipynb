{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49c81e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.getcwd() /home/carson/Desktop/Projects/language_reinforce/notebooks\n",
      "3.7.5 (default, Dec  9 2021, 17:04:37) \n",
      "[GCC 8.4.0]\n",
      "torch.__version__ 1.12.1+cu102\n",
      "0 cuda\n",
      "transformers.__version__ 4.22.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('os.getcwd()', os.getcwd())\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "print(sys.version)\n",
    "import time\n",
    "\n",
    "#plotting tools\n",
    "from matplotlib import pyplot as plt \n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "#torch libs\n",
    "import torch\n",
    "print('torch.__version__', torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipe_device = 0 if torch.cuda.is_available() else -1\n",
    "print(pipe_device, device)\n",
    "\n",
    "#huggingface transformers\n",
    "import transformers\n",
    "print('transformers.__version__',transformers.__version__)\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2PreTrainedModel\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "#curious\n",
    "from curious.models import GPT2HeadWithValueModel\n",
    "from curious.rl import PPOTrainer\n",
    "from curious.utils import LengthSampler, collater, respond_to_batch, generate_text\n",
    "\n",
    "#jupyter stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6dee75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I rented I AM CURI', '\"I Am Curious: Yellow\"', 'If only to avoid']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = torch.load('../small_data/dataloader.pth')\n",
    "\n",
    "# the dataloader is just to seed the rollout\n",
    "next(iter(dataloader))['query'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "813e07bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 2.3350484371185303},\n",
       "  {'label': 'POSITIVE', 'score': -2.726576566696167}],\n",
       " [{'label': 'NEGATIVE', 'score': -2.3049933910369873},\n",
       "  {'label': 'POSITIVE', 'score': 2.6404218673706055}]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    \"lvwerra/distilbert-imdb\", \n",
    "    device = pipe_device,\n",
    ")\n",
    "\n",
    "# reward model configs\n",
    "sent_kwargs = {\n",
    "    \"return_all_scores\": True,\n",
    "    \"function_to_apply\": \"none\",\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "text = ['this movie was really bad!!', 'i loved this movie']\n",
    "sentiments = sentiment_pipe(text, **sent_kwargs)\n",
    "\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf5ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'gpt2',\n",
    "    pad_token='<|endoftext|>',\n",
    "    padding_side = 'left',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f6f10bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['transformer.h.4.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'v_head.summary.weight', 'transformer.h.3.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'v_head.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['transformer.h.4.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'v_head.summary.weight', 'transformer.h.3.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'v_head.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#cache_folder = '/Users/carson/projects/modelstates' \n",
    "cache_folder = '/home/carson/Desktop/Projects/modelstates'\n",
    "model_name = 'distilgpt2'#'gpt2' # 'gpt2-xl' # 'gpt2-large' #\n",
    "cache_dir = os.path.join(cache_folder, model_name)\n",
    "\n",
    "gpt2_model = GPT2HeadWithValueModel.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "gpt2_model_ref = GPT2HeadWithValueModel.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "# put models onto GPU\n",
    "gpt2_model.to(device)\n",
    "gpt2_model_ref.to(device)\n",
    "\n",
    "print(gpt2_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f709240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc6b2e9de7b47b1aa59d055dcba1962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppo_trainer = PPOTrainer(gpt2_model, gpt2_model_ref, gpt2_tokenizer)\n",
    "\n",
    "total_ppo_epochs = 150\n",
    "\n",
    "for epoch, batch in tqdm(zip(range(total_ppo_epochs),iter(dataloader)),total=total_ppo_epochs):\n",
    "    \n",
    "    ### get start sequence input tokens\n",
    "    query_tensors = [torch.tensor(t).long().to(device) for t in batch[\"tokens\"]]\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "335ca885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e98abc39d5f4a63b62e01b58ed07139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e8e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
